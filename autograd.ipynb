{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0a622311",
      "metadata": {
        "id": "0a622311"
      },
      "source": [
        "\n",
        "# Diferenciação Automática com Grafos Computacionais\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faacc1a1",
      "metadata": {
        "id": "faacc1a1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19261d1f",
      "metadata": {
        "id": "19261d1f"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Union, Any\n",
        "from collections.abc import Iterable\n",
        "from abc import ABC, abstractmethod\n",
        "import numbers\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f284f531",
      "metadata": {
        "id": "f284f531"
      },
      "source": [
        "### Classe NameManager"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd00b34",
      "metadata": {
        "id": "8fd00b34"
      },
      "source": [
        "A classe NameManager provê uma forma conveniente de dar nomes intuitivos para tensores que resultam de operações. A idéia é tornar mais fácil para o usuário das demais classes qual operação gerou qual tensor. Ela provê os seguintes métodos públicos:\n",
        "\n",
        "- reset(): reinicia o sistema de gestão de nomes.\n",
        "- new(<basename>: str): retorna um nome único a partir do nome de base passado como argumento.\n",
        "  \n",
        "Como indicado no exemplo abaixo da classe, a idéia geral é que uma sequência de operações é feita, os nomes dos tensores sejam os nomes das operações seguidos de um número. Se forem feitas 3 operações de soma e uma de multiplicação, seus tensores de saída terão os nomes \"add:0\", \"add:1\", \"add:2\" e \"prod:0\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "162272a0",
      "metadata": {
        "tags": [
          "name_manager"
        ],
        "id": "162272a0",
        "outputId": "0fb39cbe-9166-4025-a1a3-fd2bc35b3eb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "add:0\n",
            "in:0\n",
            "add:1\n",
            "add:2\n",
            "in:1\n",
            "prod:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class NameManager:\n",
        "    _counts = {}\n",
        "\n",
        "    @staticmethod\n",
        "    def reset():\n",
        "        NameManager._counts = {}\n",
        "\n",
        "    @staticmethod\n",
        "    def _count(name):\n",
        "        if name not in NameManager._counts:\n",
        "            NameManager._counts[name] = 0\n",
        "        count = NameManager._counts[name]\n",
        "        return count\n",
        "\n",
        "    @staticmethod\n",
        "    def _inc_count(name):\n",
        "        assert name in NameManager._counts, f'Name {name} is not registered.'\n",
        "        NameManager._counts[name] += 1\n",
        "\n",
        "    @staticmethod\n",
        "    def new(name: str):\n",
        "        count = NameManager._count(name)\n",
        "        tensor_name = f\"{name}:{count}\"\n",
        "        NameManager._inc_count(name)\n",
        "        return tensor_name\n",
        "\n",
        "# exemplo de uso\n",
        "print(NameManager.new('add'))\n",
        "print(NameManager.new('in'))\n",
        "print(NameManager.new('add'))\n",
        "print(NameManager.new('add'))\n",
        "print(NameManager.new('in'))\n",
        "print(NameManager.new('prod'))\n",
        "\n",
        "NameManager.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e69485a9",
      "metadata": {
        "id": "e69485a9"
      },
      "source": [
        "### Classe Tensor\n",
        "\n",
        "Classe `Tensor` representando um array multidimensional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "448496d7",
      "metadata": {
        "tags": [
          "tensor"
        ],
        "id": "448496d7"
      },
      "outputs": [],
      "source": [
        "def garante_numpy_array(arr):\n",
        "  if not isinstance(arr,np.ndarray):\n",
        "    return np.array(arr,dtype=float)\n",
        "  else:\n",
        "    return arr.astype(float) # astype() só cria uma copia se o tipo for diferente\n",
        "\n",
        "class Tensor:\n",
        "    \"\"\"Classe representando um array multidimensional.\n",
        "\n",
        "    Atributos:\n",
        "\n",
        "    - _arr  (privado): dados internos do tensor como\n",
        "        um array do numpy com 2 dimensões (ver Regras)\n",
        "\n",
        "    - _parents (privado): lista de tensores que foram\n",
        "        usados como argumento para a operação que gerou o\n",
        "        tensor. Será vazia se o tensor foi inicializado com\n",
        "        valores diretamente. Por exemplo, se o tensor foi\n",
        "        resultado da operação a + b entre os tensores a e b,\n",
        "        _parents = [a, b].\n",
        "\n",
        "    - requires_grad (público): indica se devem ser\n",
        "        calculados gradientes para o tensor ou não.\n",
        "\n",
        "    - grad (público): Tensor representando o gradiente.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 # Dados do tensor. Além dos tipos listados,\n",
        "                 # arr também pode ser do tipo Tensor.\n",
        "                 arr: Union[np.ndarray, list, numbers.Number, Any],\n",
        "                 # Entradas da operacao que gerou o tensor.\n",
        "                 # Deve ser uma lista de itens do tipo Tensor.\n",
        "                 parents: list[Any] = [],\n",
        "                 # se o tensor requer o calculo de gradientes ou nao\n",
        "                 requires_grad: bool = True,\n",
        "                 # nome do tensor\n",
        "                 name: str = '',\n",
        "                 # referência para um objeto do tipo Operation (ou\n",
        "                 # subclasse) indicando qual operação gerou este\n",
        "                 # tensor. Este objeto também possui um método\n",
        "                 # para calcular a derivada da operação.\n",
        "                 operation=None):\n",
        "\n",
        "        self._arr = None\n",
        "        if isinstance(arr, Tensor):\n",
        "          self._arr = arr.numpy().copy()\n",
        "        else:\n",
        "          arr = garante_numpy_array(arr)\n",
        "\n",
        "          if arr.ndim == 0:\n",
        "            self._arr = arr.reshape(1,1)\n",
        "          elif arr.ndim == 1:\n",
        "            self._arr = arr.reshape(-1,1)\n",
        "          elif arr.ndim == 2:\n",
        "            self._arr = arr\n",
        "          else:\n",
        "            raise ValueError(f\"Entrada com {arr.ndim} dimensões não é suportada para o Tensor.\")\n",
        "\n",
        "        self._parents = parents\n",
        "\n",
        "        self.requires_grad = requires_grad\n",
        "\n",
        "        self.operation = operation\n",
        "        self.grad = None\n",
        "\n",
        "        if name:\n",
        "          self._name = name\n",
        "        else:\n",
        "          if not parents and operation is None:\n",
        "            self._name = NameManager.new('in')\n",
        "\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"\"\"Reinicia o gradiente com zero\"\"\"\n",
        "        self.grad = Tensor(np.zeros_like(self._arr))\n",
        "\n",
        "    def numpy(self):\n",
        "        \"\"\"Retorna o array interno\"\"\"\n",
        "        return self._arr\n",
        "\n",
        "    def __repr__(self):\n",
        "        \"\"\"Permite visualizar os dados do tensor como string\"\"\"\n",
        "        return f\"Tensor({self._arr}, name={self._name}, shape={self._arr.shape})\"\n",
        "\n",
        "    def backward(self, my_grad=None):\n",
        "        \"\"\"Método usado tanto iniciar o processo de\n",
        "        diferenciação automática, quanto por um filho\n",
        "        para enviar o gradiente do pai. No primeiro\n",
        "        caso, o argumento my_grad não será passado.\n",
        "        \"\"\"\n",
        "\n",
        "        # Caso seja o primeiro gradiente analisado\n",
        "        if my_grad == None:\n",
        "          self.grad = Tensor(np.ones_like(self._arr), requires_grad = False)\n",
        "        else:\n",
        "          if self.grad == None:\n",
        "            # Caso seja um tensor inicial\n",
        "            if not self._parents and self.operation is None:\n",
        "              self.grad = Tensor(np.zeros_like(self._arr), name = 'in_grad')\n",
        "            else:\n",
        "              self.grad = Tensor(np.zeros_like(self._arr), name = my_grad._name)\n",
        "\n",
        "          assert self.grad.numpy().shape == my_grad.numpy().shape\n",
        "          self.grad._arr += my_grad.numpy()\n",
        "\n",
        "        if self.operation == None:\n",
        "          return\n",
        "\n",
        "        parents_grads = self.operation.grad(self.grad,*self._parents)\n",
        "\n",
        "\n",
        "        for i, parent in enumerate(self._parents):\n",
        "          if parent.requires_grad:\n",
        "            #  print(parents_grads[i])\n",
        "            #  print('----------------------------------------------------------------\\n')\n",
        "             parent.backward(my_grad = parents_grads[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c612fc",
      "metadata": {
        "id": "d2c612fc"
      },
      "source": [
        "### Interface de  Operações"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7db44044",
      "metadata": {
        "id": "7db44044"
      },
      "source": [
        "A classe abaixo define a interface que as operações devem implementar. Ela não precisa ser modificada, mas pode, caso queira."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28a19b73",
      "metadata": {
        "tags": [
          "op"
        ],
        "id": "28a19b73"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Op(ABC):\n",
        "    @abstractmethod\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "        \"\"\"Realiza a operação usando as entradas e\n",
        "            retorna o tensor resultado.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "        \"\"\"Retorna os gradientes dos pais em como tensores.\n",
        "\n",
        "        Arguments:\n",
        "\n",
        "        - back_grad: Derivada parcial em relação à saída\n",
        "            da operação backpropagada pelo filho.\n",
        "\n",
        "        - args: variaveis de entrada da operacao (pais)\n",
        "            como tensores.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "    # GARANTE QUE ARGS SAO TENSORES\n",
        "    def _ts(self,args):\n",
        "      tensor_elements = []\n",
        "      for elemento in args:\n",
        "        if not isinstance(elemento,Tensor):\n",
        "          elemento_tensor = Tensor(arr=elemento,requires_grad=False)\n",
        "          tensor_elements.append(elemento_tensor)\n",
        "        else:\n",
        "          tensor_elements.append(elemento)\n",
        "      return tuple(tensor_elements)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b89e386",
      "metadata": {
        "id": "9b89e386"
      },
      "source": [
        "### Implementação das Operações\n",
        "\n",
        "Operações devem herdar de `Op` e implementar os métodos `__call__` e `grad`.\n",
        "\n",
        "Pelo menos as seguintes operações devem ser implementadas:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa4f7719",
      "metadata": {
        "tags": [
          "add"
        ],
        "id": "aa4f7719"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Add(Op):\n",
        "    \"\"\"Add(a, b): a + b\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "         \"\"\"Realiza a operação usando os argumentos dados em args\"\"\"\n",
        "        args = self._ts(args)\n",
        "        assert args[0].numpy().shape == args[1].numpy().shape or \\\n",
        "           args[0].numpy().size == 1 or args[1].numpy().size == 1, \\\n",
        "           f\"Shapes para Add devem ser iguais ou um deve ser escalar: {args[0].numpy().shape}, {args[1].numpy().shape}\"\n",
        "\n",
        "        result = args[0].numpy() + args[1].numpy()\n",
        "        return Tensor(result,parents=args,name = NameManager.new('add'),operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "        \"\"\"Retorna a lista de derivadas parciais em relação aos pais (passados em args)\"\"\"\n",
        "        return [Tensor(back_grad, name=NameManager.new('add_grad')),Tensor(back_grad, name=NameManager.new('add_grad'))] # No caso é backgrad * 1 pois eh uma soma. backgrad = grad do filho\n",
        "\n",
        "\n",
        "\n",
        "# Instancia a classe. O objeto passa a poder ser usado como uma funcao\n",
        "add = Add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05cb44e6",
      "metadata": {
        "tags": [
          "sub"
        ],
        "id": "05cb44e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sub(Op):\n",
        "    \"\"\"Sub(a, b): a - b\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        assert args[0].numpy().shape == args[1].numpy().shape or \\\n",
        "           args[0].numpy().size == 1 or args[1].numpy().size == 1, \\\n",
        "           f\"Shapes para Add devem ser iguais ou um deve ser escalar: {args[0].numpy().shape}, {args[1].numpy().shape}\"\n",
        "\n",
        "        result = args[0].numpy() - args[1].numpy()\n",
        "        return Tensor(result,parents=args,name = NameManager.new('sub'),operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "        return [Tensor(back_grad, name=NameManager.new('sub_grad')),Tensor(back_grad._arr * (-1), name=NameManager.new('sub_grad'))]\n",
        "\n",
        "\n",
        "sub = Sub()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dt1ya-GAwCAy"
      },
      "id": "dt1ya-GAwCAy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f53df08",
      "metadata": {
        "tags": [
          "prod"
        ],
        "id": "6f53df08"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Prod(Op):\n",
        "    \"\"\"Prod(a, b): produto ponto a ponto de a e b ou produto escalar-tensor\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "        args = self._ts(args)\n",
        "\n",
        "        assert args[0].numpy().shape == args[1].numpy().shape or \\\n",
        "           args[0].numpy().size == 1 or args[1].numpy().size == 1, \\\n",
        "           f\"Shapes para Add devem ser iguais ou um deve ser escalar: {args[0].numpy().shape}, {args[1].numpy().shape}\"\n",
        "\n",
        "        result = args[0].numpy() * args[1].numpy()\n",
        "        return Tensor(result,parents=args,name = NameManager.new('prod'),operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "        return [Tensor(self(back_grad,args[1]), name=NameManager.new('prod_grad')),Tensor(self(back_grad,args[0]), name=NameManager.new('prod_grad'))]\n",
        "\n",
        "\n",
        "prod = Prod()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f3838a7",
      "metadata": {
        "tags": [
          "sin"
        ],
        "id": "8f3838a7"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sin(Op):\n",
        "    \"\"\"seno element-wise\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        result = np.sin(args[0].numpy())\n",
        "        return Tensor(result,parents=args,name = NameManager.new('sin'),operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "        \"\"\"Retorna a lista de derivadas parciais em relação aos pais (passados em args)\"\"\"\n",
        "        result_sin_grad = np.cos(args[0]._arr) * back_grad._arr\n",
        "        return [Tensor(result_sin_grad, name=NameManager.new('sin_grad'))]\n",
        "\n",
        "\n",
        "sin = Sin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138cb8ef",
      "metadata": {
        "tags": [
          "cos"
        ],
        "id": "138cb8ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Cos(Op):\n",
        "    \"\"\"cosseno element-wise\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        result = np.cos(args[0].numpy())\n",
        "        return Tensor(result,parents=args,name = NameManager.new('cos'),operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "        result_cos_grad = np.sin(args[0]._arr) * (-1) * back_grad._arr\n",
        "        return [Tensor(result_cos_grad, name=NameManager.new('cos_grad'))]\n",
        "\n",
        "\n",
        "\n",
        "cos = Cos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46eac52c",
      "metadata": {
        "tags": [
          "sum"
        ],
        "id": "46eac52c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sum(Op):\n",
        "    \"\"\"Retorna a soma dos elementos do tensor\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        result = np.sum(args[0].numpy())\n",
        "        return Tensor(result,parents=args,name = NameManager.new('my_sum'),operation=self)\n",
        "\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "        ones = Tensor(np.ones_like(args[0].numpy()))\n",
        "        return [Tensor(prod(ones,back_grad), name=NameManager.new('my_sum_grad'))]\n",
        "\n",
        "\n",
        "my_sum = Sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e098a39c",
      "metadata": {
        "tags": [
          "mean"
        ],
        "id": "e098a39c"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Mean(Op):\n",
        "    \"\"\"Retorna a média dos elementos do tensor\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "        args = self._ts(args)\n",
        "        result = np.mean(args[0].numpy())\n",
        "        return Tensor(result,parents=args,name = NameManager.new('mean'),operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "        n_elementos = args[0].numpy().size\n",
        "        ones = Tensor(np.ones_like(args[0].numpy()))\n",
        "\n",
        "        result_mean_grad = back_grad._arr / n_elementos\n",
        "\n",
        "        return [Tensor(prod(ones,result_mean_grad), name=NameManager.new('mean_grad'))]\n",
        "\n",
        "\n",
        "mean = Mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37692879",
      "metadata": {
        "tags": [
          "square"
        ],
        "id": "37692879"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Square(Op):\n",
        "    \"\"\"Eleva cada elemento ao quadrado\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "        args = self._ts(args)\n",
        "        result = np.power(args[0].numpy(),2)\n",
        "        return Tensor(result,parents=args,name = NameManager.new('square'),operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "        result_square_grad = 2 * args[0].numpy() * back_grad._arr\n",
        "        return [Tensor(result_square_grad,name = NameManager.new('square_grad'))]\n",
        "\n",
        "\n",
        "square = Square()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6542807d",
      "metadata": {
        "tags": [
          "matmul"
        ],
        "id": "6542807d"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MatMul(Op):\n",
        "    \"\"\"MatMul(A, B): multiplicação de matrizes\n",
        "\n",
        "    C = A @ B\n",
        "    de/dA = de/dc @ B^T\n",
        "    de/dB = A^T @ de/dc\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "        args = self._ts(args)\n",
        "        assert args[0].numpy().shape[1] == args[1].numpy().shape[0], \\\n",
        "            f\"Shape incompatível para MatMul: {args[0].numpy().shape} @ {args[1].numpy().shape}\"\n",
        "\n",
        "        result = args[0].numpy() @ args[1].numpy()\n",
        "        return Tensor(result, parents=args, name=NameManager.new('matmul'), operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "        A = args[0]\n",
        "        B = args[1]\n",
        "\n",
        "        grad_A = self(back_grad._arr,B._arr.T)\n",
        "        grad_B = self(A._arr.T,back_grad)\n",
        "\n",
        "        return [Tensor(grad_A,name= NameManager.new('matmul_grad')), Tensor(grad_B,name= NameManager.new('matmul_grad'))]\n",
        "\n",
        "\n",
        "matmul = MatMul()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08a38e3",
      "metadata": {
        "tags": [
          "exp"
        ],
        "id": "c08a38e3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Exp(Op):\n",
        "    \"\"\"Exponenciação element-wise\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "        args = self._ts(args)\n",
        "        result = np.exp(args[0]._arr)\n",
        "        return Tensor(result, parents=args, name=NameManager.new('exp'), operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "        result_exp_grad = np.exp(args[0].numpy()) * back_grad.numpy()\n",
        "\n",
        "        return [Tensor(result_exp_grad, name = NameManager.new('exp_grad'))]\n",
        "\n",
        "exp = Exp()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1acc813e",
      "metadata": {
        "tags": [
          "relu"
        ],
        "id": "1acc813e"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ReLU(Op):\n",
        "    \"\"\"ReLU element-wise\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        result = np.maximum(0, args[0].numpy())\n",
        "        return Tensor(result, parents=args, name=NameManager.new('relu'), operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "        mask = args[0].numpy() > 0\n",
        "        mask_float = mask.astype(float)\n",
        "\n",
        "        result_relu_grad = back_grad.numpy() * mask_float\n",
        "\n",
        "        return [Tensor(result_relu_grad,name = NameManager.new('relu_grad'))]\n",
        "\n",
        "relu = ReLU()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae499275",
      "metadata": {
        "tags": [
          "sigmoid"
        ],
        "id": "ae499275"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sigmoid(Op):\n",
        "    \"\"\"Sigmoid element-wise\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        result = 1 / (1+ np.exp(-args[0].numpy()))\n",
        "        return Tensor(result, parents=args, name=NameManager.new('sigmoid'), operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "        y = self(args[0].numpy())\n",
        "        result_sigmoid_grad = y.numpy() * (1 - y.numpy()) # y * (1 - y)\n",
        "        result_sigmoid_grad = result_sigmoid_grad * back_grad.numpy()\n",
        "\n",
        "\n",
        "        return [Tensor(result_sigmoid_grad, name = NameManager.new('sigmoid_grad'))]\n",
        "\n",
        "\n",
        "sigmoid = Sigmoid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce464ba",
      "metadata": {
        "tags": [
          "tanh"
        ],
        "id": "6ce464ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Tanh(Op):\n",
        "    \"\"\"Tanh element-wise\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        result = np.tanh(args[0].numpy())\n",
        "        return Tensor(result, parents=args, name=NameManager.new('tanh'), operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "        # Derivada de tanh = 1 - tanh^2(x)\n",
        "        y = self(args[0].numpy())\n",
        "        y_quadrado = square(y)\n",
        "\n",
        "        result_tanh_grad = (1 - y_quadrado.numpy()) * back_grad.numpy()\n",
        "\n",
        "        return [Tensor(result_tanh_grad,name = NameManager.new('tanh_grad'))]\n",
        "\n",
        "\n",
        "\n",
        "tanh = Tanh()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15a37eb",
      "metadata": {
        "tags": [
          "softmax"
        ],
        "id": "f15a37eb"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Softmax(Op):\n",
        "    \"\"\"Softmax de um array de valores. Lembre-se que cada elemento do array influencia o resultado da função para todos os demais elementos.\"\"\"\n",
        "    def __call__(self, *args, **kwargs) -> Tensor:\n",
        "\n",
        "        args = self._ts(args)\n",
        "        exps = np.exp(args[0].numpy() - np.max(args[0].numpy(), axis = 0,keepdims=True)) # previne que e^x exploda para valores grandes\n",
        "\n",
        "        result = exps / np.sum(exps,axis=0,keepdims=True)\n",
        "        return Tensor(result, parents=args, name=NameManager.new('softmax'), operation=self)\n",
        "\n",
        "    def grad(self, back_grad: Tensor, *args, **kwargs) -> list[Tensor]:\n",
        "\n",
        "         # dL/dx = y * (dL/dy - my_sum(dL/dy * y))\n",
        "        y = self(args[0].numpy())\n",
        "\n",
        "        dot_product = np.sum(back_grad.numpy() * y.numpy())\n",
        "        sub_result = back_grad.numpy() - dot_product\n",
        "\n",
        "        result_softmax_grad = y.numpy() * sub_result\n",
        "\n",
        "        return [Tensor(result_softmax_grad,name = NameManager.new('softmax_grad'))]\n",
        "\n",
        "\n",
        "softmax = Softmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12256fd7",
      "metadata": {
        "id": "12256fd7"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc927248",
      "metadata": {
        "id": "fc927248"
      },
      "source": [
        "## Testes Básicos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5ae08a8",
      "metadata": {
        "id": "c5ae08a8"
      },
      "source": [
        "Estes testes avaliam se a derivada da função está sendo calculada corretamente, mas em muitos casos **não** avaliam se os gradientes backpropagados estão sendo incorporados corretamente. Esta avaliação será feita nos problemas da próxima seção."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b05318a9",
      "metadata": {
        "id": "b05318a9"
      },
      "source": [
        "Operador de Soma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd20550",
      "metadata": {
        "tags": [
          "test_add"
        ],
        "id": "9fd20550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41412555-f105-408f-b210-61aa8b859883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[1.]\n",
            " [1.]\n",
            " [1.]], name=in_grad, shape=(3, 1))\n",
            "Tensor([[1.]\n",
            " [1.]\n",
            " [1.]], name=in_grad, shape=(3, 1))\n"
          ]
        }
      ],
      "source": [
        "# add\n",
        "\n",
        "a = Tensor([1.0, 2.0, 3.0])\n",
        "b = Tensor([4.0, 5.0, 6.0])\n",
        "c = add(a, b)\n",
        "d = add(c, 3.0)\n",
        "d.backward()\n",
        "\n",
        "# esperado: matrizes coluna contendo 1\n",
        "print(a.grad)\n",
        "print(b.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac72b1a",
      "metadata": {
        "id": "fac72b1a"
      },
      "source": [
        "Operador de Subtração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "612377aa",
      "metadata": {
        "tags": [
          "test_sub"
        ],
        "id": "612377aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93392d3f-bccc-40de-f3aa-dbc9533bb50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[1.]\n",
            " [1.]\n",
            " [1.]], name=in_grad, shape=(3, 1))\n",
            "Tensor([[-1.]\n",
            " [-1.]\n",
            " [-1.]], name=in_grad, shape=(3, 1))\n"
          ]
        }
      ],
      "source": [
        "# sub\n",
        "\n",
        "a = Tensor([1.0, 2.0, 3.0])\n",
        "b = Tensor([4.0, 5.0, 6.0])\n",
        "c = sub(a, b)\n",
        "d = sub(c, 3.0)\n",
        "d.backward()\n",
        "\n",
        "# esperado: matrizes coluna contendo 1 e -1\n",
        "print(a.grad)\n",
        "print(b.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c7c8e63",
      "metadata": {
        "id": "9c7c8e63"
      },
      "source": [
        "Operador de Produto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc60de82",
      "metadata": {
        "tags": [
          "test_prod"
        ],
        "id": "dc60de82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9825926f-afa1-424a-b9ae-055ad6b20299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[12.]\n",
            " [15.]\n",
            " [18.]], name=in_grad, shape=(3, 1))\n",
            "Tensor([[3.]\n",
            " [6.]\n",
            " [9.]], name=in_grad, shape=(3, 1))\n"
          ]
        }
      ],
      "source": [
        "# prod\n",
        "\n",
        "a = Tensor([1.0, 2.0, 3.0])\n",
        "b = Tensor([4.0, 5.0, 6.0])\n",
        "c = prod(a, b)\n",
        "d = prod(c, 3.0)\n",
        "d.backward()\n",
        "\n",
        "# esperado: [12, 15, 18]^T\n",
        "print(a.grad)\n",
        "# esperado: [3, 6, 9]^T\n",
        "print(b.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d91e1c3",
      "metadata": {
        "id": "5d91e1c3"
      },
      "source": [
        "Operadores trigonométricos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6185a989",
      "metadata": {
        "tags": [
          "test_sin_cos"
        ],
        "id": "6185a989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0af2cd2-58cf-418e-f796-e20ace58cb21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[-1.]\n",
            " [ 1.]\n",
            " [-1.]], name=in_grad, shape=(3, 1))\n"
          ]
        }
      ],
      "source": [
        "# sin e cos\n",
        "\n",
        "a = Tensor([np.pi, 0, np.pi/2])\n",
        "b = sin(a)\n",
        "c = cos(a)\n",
        "d = my_sum(add(b, c))\n",
        "d.backward()\n",
        "\n",
        "# esperado: [-1, 1, -1]^T\n",
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f29f232",
      "metadata": {
        "tags": [
          "test_sum"
        ],
        "id": "5f29f232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157a195d-4ff9-460c-a4f4-170b8e206029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[4.]\n",
            " [4.]\n",
            " [4.]\n",
            " [4.]], name=in_grad, shape=(4, 1))\n"
          ]
        }
      ],
      "source": [
        "# Sum\n",
        "\n",
        "a = Tensor([3.0, 1.0, 0.0, 2.0])\n",
        "b = add(prod(a, 3.0), a)\n",
        "c = my_sum(b)\n",
        "c.backward()\n",
        "\n",
        "# esperado: [4, 4, 4, 4]^T\n",
        "print(a.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8943e71a",
      "metadata": {
        "tags": [
          "test_mean"
        ],
        "id": "8943e71a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9a9a65-963b-4826-bea9-2d5e8ba5173f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[0.25]\n",
            " [0.25]\n",
            " [0.25]\n",
            " [0.25]], name=in_grad, shape=(4, 1))\n"
          ]
        }
      ],
      "source": [
        "# Mean\n",
        "\n",
        "a = Tensor([3.0, 1.0, 0.0, 2.0])\n",
        "b = mean(a)\n",
        "b.backward()\n",
        "\n",
        "# esperado: [0.25, 0.25, 0.25, 0.25]^T\n",
        "print(a.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c7dbd2c",
      "metadata": {
        "tags": [
          "test_square"
        ],
        "id": "1c7dbd2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70715022-e4cb-4072-a388-ae29cab7b55b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[9.]\n",
            " [1.]\n",
            " [0.]\n",
            " [4.]], name=square:0, shape=(4, 1))\n",
            "Tensor([[6.]\n",
            " [2.]\n",
            " [0.]\n",
            " [4.]], name=in_grad, shape=(4, 1))\n"
          ]
        }
      ],
      "source": [
        "# Square\n",
        "\n",
        "a = Tensor([3.0, 1.0, 0.0, 2.0])\n",
        "b = square(a)\n",
        "\n",
        "# esperado: [9, 1, 0, 4]^T\n",
        "print(b)\n",
        "\n",
        "b.backward()\n",
        "\n",
        "# esperado: [6, 2, 0, 4]\n",
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f2ead7",
      "metadata": {
        "tags": [
          "test_matmul"
        ],
        "id": "02f2ead7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf6be24-31b1-40e5-eff1-678fa109303d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[14.]\n",
            " [32.]\n",
            " [50.]], name=matmul:0, shape=(3, 1))\n",
            "Tensor([[1. 2. 3.]\n",
            " [1. 2. 3.]\n",
            " [1. 2. 3.]], name=in_grad, shape=(3, 3))\n",
            "Tensor([[12.]\n",
            " [15.]\n",
            " [18.]], name=in_grad, shape=(3, 1))\n"
          ]
        }
      ],
      "source": [
        "# matmul\n",
        "\n",
        "W = Tensor([\n",
        "    [1.0, 2.0, 3.0],\n",
        "    [4.0, 5.0, 6.0],\n",
        "    [7.0, 8.0, 9.0]\n",
        "])\n",
        "\n",
        "v = Tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "z = matmul(W, v)\n",
        "\n",
        "# esperado: [14, 32, 50]^T\n",
        "print(z)\n",
        "\n",
        "z.backward()\n",
        "\n",
        "# esperado:\n",
        "# [1, 2, 3]\n",
        "# [1, 2, 3]\n",
        "# [1, 2, 3]\n",
        "print(W.grad)\n",
        "\n",
        "# esperado: [12, 15, 18]^T\n",
        "print(v.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "706212d2",
      "metadata": {
        "tags": [
          "test_exp"
        ],
        "id": "706212d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3e29ac-3b73-4010-86ae-9c40652b06b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[ 2.71828183]\n",
            " [ 7.3890561 ]\n",
            " [20.08553692]], name=exp:0, shape=(3, 1))\n",
            "Tensor([[ 2.71828183]\n",
            " [ 7.3890561 ]\n",
            " [20.08553692]], name=in_grad, shape=(3, 1))\n"
          ]
        }
      ],
      "source": [
        "# Exp\n",
        "\n",
        "v = Tensor([1.0, 2.0, 3.0])\n",
        "w = exp(v)\n",
        "\n",
        "# esperado: [2.718..., 7.389..., 20.085...]^T\n",
        "print(w)\n",
        "\n",
        "w.backward()\n",
        "\n",
        "# esperado: [2.718..., 7.389..., 20.085...]^T\n",
        "print(v.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9510d010",
      "metadata": {
        "tags": [
          "test_relu"
        ],
        "id": "9510d010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b073d3e6-2199-4963-dfe6-7786495b4230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [3.]], name=relu:0, shape=(4, 1))\n",
            "Tensor([[0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]], name=in_grad, shape=(4, 1))\n"
          ]
        }
      ],
      "source": [
        "# Relu\n",
        "\n",
        "v = Tensor([-1.0, 0.0, 1.0, 3.0])\n",
        "w = relu(v)\n",
        "\n",
        "# esperado: [0, 0, 1, 3]^T\n",
        "print(w)\n",
        "\n",
        "w.backward()\n",
        "\n",
        "# esperado: [0, 0, 1, 1]^T\n",
        "print(v.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f0fbf8d",
      "metadata": {
        "tags": [
          "test_sigmoid"
        ],
        "id": "2f0fbf8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff4fc64-ee46-4011-fbdc-92f0cbeee323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[0.26894142]\n",
            " [0.5       ]\n",
            " [0.73105858]\n",
            " [0.95257413]], name=sigmoid:0, shape=(4, 1))\n",
            "Tensor([[0.19661193]\n",
            " [0.25      ]\n",
            " [0.19661193]\n",
            " [0.04517666]], name=in_grad, shape=(4, 1))\n"
          ]
        }
      ],
      "source": [
        "# Sigmoid\n",
        "\n",
        "v = Tensor([-1.0, 0.0, 1.0, 3.0])\n",
        "w = sigmoid(v)\n",
        "\n",
        "# esperado: [0.268.., 0.5, 0.731.., 0.952..]^T\n",
        "print(w)\n",
        "\n",
        "w.backward()\n",
        "\n",
        "# esperado: [0.196..., 0.25, 0.196..., 0.045...]^T\n",
        "print(v.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e867dec",
      "metadata": {
        "tags": [
          "test_tanh"
        ],
        "id": "7e867dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2fac346-6cce-49e9-9059-55506491a94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[-0.76159416]\n",
            " [ 0.        ]\n",
            " [ 0.76159416]\n",
            " [ 0.99505475]], name=tanh:0, shape=(4, 1))\n",
            "Tensor([[0.41997434]\n",
            " [1.        ]\n",
            " [0.41997434]\n",
            " [0.00986604]], name=in_grad, shape=(4, 1))\n"
          ]
        }
      ],
      "source": [
        "# Tanh\n",
        "\n",
        "v = Tensor([-1.0, 0.0, 1.0, 3.0])\n",
        "w = tanh(v)\n",
        "\n",
        "# esperado: [[-0.76159416, 0., 0.76159416, 0.99505475]^T\n",
        "print(w)\n",
        "\n",
        "w.backward()\n",
        "\n",
        "# esperado: [0.41997434, 1., 0.41997434, 0.00986604]^T\n",
        "print(v.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd3235d",
      "metadata": {
        "tags": [
          "test_softmax"
        ],
        "id": "7fd3235d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b39677-d475-4650-8437-801befbdd22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor([[0.00381737]\n",
            " [0.13970902]\n",
            " [0.23034123]\n",
            " [0.62613238]], name=softmax:0, shape=(4, 1))\n",
            "MSE: Tensor([[0.36424932]], name=mean:1, shape=(1, 1))\n",
            "Tensor([[-0.00278095]\n",
            " [-0.02243068]\n",
            " [-0.02654377]\n",
            " [ 0.05175539]], name=in_grad, shape=(4, 1))\n"
          ]
        }
      ],
      "source": [
        "# Softmax\n",
        "\n",
        "x = Tensor([-3.1, 0.5, 1.0, 2.0])\n",
        "y = softmax(x)\n",
        "\n",
        "# esperado: [0.00381737, 0.13970902, 0.23034123, 0.62613238]^T\n",
        "print(y)\n",
        "\n",
        "# como exemplo, calcula o MSE para um target vector\n",
        "diff = sub(y, [1, 0, 0, 0])\n",
        "sq = square(diff)\n",
        "a = mean(sq)\n",
        "\n",
        "# esperado: 0.36424932\n",
        "print(\"MSE:\", a)\n",
        "\n",
        "a.backward()\n",
        "\n",
        "# esperado: [-0.00278095, -0.02243068, -0.02654377, 0.05175539]^T\n",
        "print(x.grad)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "venv_main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}